{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "cupoy_env",
      "language": "python",
      "name": "cupoy_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "決策樹作業.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou9EXlg3yeWc"
      },
      "source": [
        "### 作業目的:了解決策樹的節點分支依據\n",
        "本次作業可參考簡報中的延伸閱讀[訊息增益](https://medium.com/jameslearningnote/%E8%B3%87%E6%96%99%E5%88%86%E6%9E%90-%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92-%E7%AC%AC3-5%E8%AC%9B-%E6%B1%BA%E7%AD%96%E6%A8%B9-decision-tree-%E4%BB%A5%E5%8F%8A%E9%9A%A8%E6%A9%9F%E6%A3%AE%E6%9E%97-random-forest-%E4%BB%8B%E7%B4%B9-7079b0ddfbda)部分"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVxE1nHIyeWj"
      },
      "source": [
        "#### Question:\n",
        "若你是決策樹，下列兩種分類狀況(a,b)，你會選擇哪種做分類？為什麼？\n",
        "\n",
        "<img src='hw_1.png' style='width:500px'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EnI7XX-yeWj"
      },
      "source": [
        "### Answer:\n",
        "\n",
        "選擇a"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0SHsZLl2w1h",
        "outputId": "c0bed750-02d4-47dc-aeb0-3c93d5b39835"
      },
      "source": [
        "import math\n",
        "#Gini\n",
        "a_gini_p = 1-(1/2)**2-(1/2)**2\n",
        "a_gini_left = 1-(3/4)**2-(1/4)**2\n",
        "a_gini_right = 1-(1/4)**2-(3/4)**2\n",
        "total_gini_a = a_gini_p-(2/4)*a_gini_left-(2/4)*a_gini_right\n",
        "\n",
        "b_gini_p = 1-(1/2)**2-(1/2)**2\n",
        "b_gini_left = 1-(3/4)**2-(4/4)**2\n",
        "b_gini_right = 1-(1/4)**2-(0)**2\n",
        "total_gini_b = b_gini_p- 2/4*b_gini_left - 2/4*b_gini_right\n",
        "print(f'Total Gini of a = {total_gini_a}')\n",
        "print(f'Total Gini of b = {total_gini_b}')\n",
        "\n",
        "#Entropy\n",
        "a_E_p = -((1/2*math.log2(1/2))+(1/2*math.log2(1/2)))\n",
        "a_E_left = -((3/4*math.log2(3/4))+(1/4*math.log2(1/4)))\n",
        "a_E_right = -((1/4*math.log2(1/4))+(3/4*math.log2(3/4)))\n",
        "total_E_a = a_E_p - 2/4*a_E_left - 2/4*a_E_right\n",
        "\n",
        "b_E_p = -((1/2*math.log2(1/2))+(1/2*math.log2(1/2)))\n",
        "b_E_left = -((3/4*math.log2(3/4))+(4/4*math.log2(4/4)))\n",
        "b_E_right = -((1/4*math.log2(1/4))+0)\n",
        "total_E_b = b_E_p - 2/4*b_E_left - 2/4*b_E_right\n",
        "\n",
        "print(f'Total Entropy of a = {total_E_a}')\n",
        "print(f'Total Entropy of b = {total_E_b}')\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Gini of a = 0.125\n",
            "Total Gini of b = 0.3125\n",
            "Total Entropy of a = 0.1887218755408671\n",
            "Total Entropy of b = 0.5943609377704335\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZ2aiutAyeWk"
      },
      "source": [
        "### 閱讀作業\n",
        "\n",
        "決策樹根據計算分割準則的不同(ex: Entropy, Gini, Gain ratio)，可分為ID3, C4.5, CART樹的算法，請同學閱讀下列文章，來更加了解決策樹的算法。\n",
        "\n",
        "[決策樹(ID3, C4.5, CART)](https://blog.csdn.net/u010089444/article/details/53241218)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YnjO2E9UnEM"
      },
      "source": [
        "### ID3(分割準則：Entropy -> Information gain):\n",
        "選擇訊息增益量最大的作為分支標準\n",
        "缺點：\n",
        "偏向選擇有多種類值的項目作為分支\n",
        "ID3不能處理連續型的的數據特徵\n",
        "\n",
        "### C4.5(分割準則：Gain ratio)\n",
        "以ID3演算法改善而成，解決上述ID3的兩個主要問題\n",
        "選擇分支的標準改成Gain ratio\n",
        "針對連續型的屬性則先將其轉換成離散屬性再進行處理\n",
        "\n",
        "\n",
        "### CART(分割準則：Gini Index)\n",
        "GINI:介於0~1的數字，數字愈小樣本純淨度愈高 =>GINI指數可以理解成隨機在數據集中抽取2個樣本時，其類別不一致的機率\n"
      ]
    }
  ]
}