{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "手刻貝氏-作業.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMRAYecHvnKE"
      },
      "source": [
        "# 手刻基本Naive Bayes模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UONOOr6TvvKh",
        "outputId": "eee8c9f5-d262-4934-faee-5641e142fac6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqkJHF3ZvnKL"
      },
      "source": [
        "#### 學習重點：理解單純貝氏模型原理"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f88SQqQvnKM"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEK7BQISvnKM"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "import glob\n",
        "import codecs\n",
        "\n",
        "from collections import defaultdict\n",
        "from collections import Counter\n",
        "\n",
        "def tokenize(message):\n",
        "    message=message.lower()\n",
        "    all_words=re.findall(\"[a-z0-9]+\",message)\n",
        "    return set(all_words)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7YzwQIaOvnKP"
      },
      "source": [
        "### 讀入資料並分割為 train/testset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_XU2ogLvnKQ"
      },
      "source": [
        "X = []\n",
        "Y = []\n",
        "paths =[r'/content/drive/MyDrive/NLP/spam_data/spam', r'/content/drive/MyDrive/NLP/spam_data/easy_ham', r'/content/drive/MyDrive/NLP/spam_data/hard_ham'] \n",
        "for path in paths:\n",
        "    for fn in glob.glob(path+\"/*\"):\n",
        "        if \"ham\" not in fn:\n",
        "            is_spam = True\n",
        "        else:\n",
        "            is_spam = False\n",
        "        #codecs.open可以避開錯誤，用errors='ignore'\n",
        "        with codecs.open(fn,encoding='utf-8', errors='ignore') as file:\n",
        "            for line in file:\n",
        "                #這個line的開頭為Subject:\n",
        "                if line.startswith(\"Subject:\"):\n",
        "                    subject=re.sub(r\"^Subject:\",\"\",line).strip()\n",
        "                    X.append(subject)\n",
        "                    Y.append(is_spam)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahVO8L34woIa",
        "outputId": "e5fcb3f9-46c3-460f-e7d0-1c276fc3df37"
      },
      "source": [
        "len(X)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3423"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vm8JfO5RvnKQ"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# random_state 是為了讓各為學員得到相同的結果，平時可以移除\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BiQDklTvnKQ"
      },
      "source": [
        "train_data = []\n",
        "test_data = []\n",
        "\n",
        "for x_, y_ in zip(X_train, y_train):\n",
        "    train_data.append([x_, y_])\n",
        "\n",
        "for x_, y_ in zip(X_test, y_test):\n",
        "    test_data.append([x_, y_])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjzKptuC5-CU",
        "outputId": "31b6597f-5f14-447d-ae58-85526ca33dc1"
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Re: Problem with an rpm...', False]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvi7iBOEvnKR"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "achv5UgpvnKR"
      },
      "source": [
        "### defaultdict用法示範"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e210qjAuvnKR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52897115-184e-462e-edc9-b52347b29a5b"
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "mess='This is our first time in Taiwan,,,,, such a beautiful contury'\n",
        "\n",
        "counts=defaultdict(lambda:[0,0])\n",
        "counts['you'][0]+=1\n",
        "counts['hi'][0]+=1\n",
        "counts['hi'][1]+=2\n",
        "counts['no'][1]+=1\n",
        "counts['no'][0]+=8\n",
        "print('dic : {}'.format(counts))\n",
        "print('you : {}'.format(counts['you']))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dic : defaultdict(<function <lambda> at 0x7f93cda33290>, {'you': [1, 0], 'hi': [1, 2], 'no': [8, 1]})\n",
            "you : [1, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzUNHBb9vnKS"
      },
      "source": [
        "### 創造一個字典，裡面是{'hi': [1, 0]}，對應第一個數字是是垃圾郵件的次數，對應第二個數字是不是垃圾郵件的次數"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On-GFLdSvnKT"
      },
      "source": [
        "def count_words(training_set):\n",
        "    counts=defaultdict(lambda:[0,0])\n",
        "    for message,is_spam in training_set:\n",
        "        for word in tokenize(message):\n",
        "            '''list[0]為出現在spam中的次數，list[1]為出現在ham(非spam)中的次數'''\n",
        "            counts[word][0 if is_spam else 1]+=1\n",
        "    return counts"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PL3ZiRiEvnKT"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQ66Gf58vnKT"
      },
      "source": [
        "## 計算 p(w|spam) / p(w|non_spam)\n",
        "* 其中K為超參數，為了確保分母/分子皆不為0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bc5yjYMWvnKU"
      },
      "source": [
        "def word_probabilities(counts,total_spams,total_non_spams,k=0.5):\n",
        "    #獲得三組數據，分別為w這個字，p(w|spam)，p(w|non_spam)\n",
        "    #counts[w][0]=spam,counts[w][1]=non_spam\n",
        "\n",
        "    return [(w,(counts[w][0]+k)/(total_spams+2*k),(counts[w][1]+k)/(total_non_spams+2*k)) for w in counts]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSOts2lhvnKU"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4FPswMsvnKU"
      },
      "source": [
        "## 計算貝氏結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQAU8LUsvnKU"
      },
      "source": [
        "def spam_probability(word_probs,message, is_spam_probability, is_not_spam_probability):\n",
        "    #先把這個mail的文字處理一下\n",
        "    message_words=tokenize(message)\n",
        "    #初始化值\n",
        "    log_prob_if_spam=log_prob_if_not_spam=0.0\n",
        "    #將w這個字，p(w|spam)，p(w|non_spam)依序引入\n",
        "    for word,prob_if_spam,prob_if_not_spam in word_probs:\n",
        "        if word in message_words:\n",
        "            #假如這個字有在這個mail中出現\n",
        "            #把他的p(w|spam)轉log值加上log_prob_if_spam\n",
        "            log_prob_if_spam = log_prob_if_spam+math.log(prob_if_spam)\n",
        "            #把他的p(w|non_spam)轉log值加上log_prob_if_not_spam\n",
        "            log_prob_if_not_spam= log_prob_if_not_spam+math.log(prob_if_not_spam)\n",
        "        else:\n",
        "            #如果沒出現log_prob_if_spam加上的值就是1-p(w|spam)也就是這封信是垃圾郵件但是w這個字卻沒在裡面\n",
        "            log_prob_if_spam=log_prob_if_spam+math.log(1-prob_if_spam)\n",
        "            log_prob_if_not_spam=log_prob_if_not_spam+math.log(1-prob_if_not_spam)\n",
        "\n",
        "    log_prob_if_spam = log_prob_if_spam+math.log(is_spam_probability)\n",
        "    log_prob_if_not_spam = log_prob_if_not_spam+math.log(is_not_spam_probability)\n",
        "    \n",
        "    #把+起來的值轉成exp再算NaiveBayes\n",
        "    prob_if_spam=math.exp(log_prob_if_spam)\n",
        "    prob_if_not_spam=math.exp(log_prob_if_not_spam)\n",
        "    #貝氏\n",
        "    return prob_if_spam/(prob_if_spam+prob_if_not_spam)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7ZBG1cCvnKV"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfwAcpFQvnKV"
      },
      "source": [
        "### 打包整個模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsWik4pGvnKV"
      },
      "source": [
        "class NaiveBayesClassifier:\n",
        "    def __init__(self,k=0.5):\n",
        "        self.k=k\n",
        "        self.word_probs=[]\n",
        "    def train(self,training_set):\n",
        "        #訓練的資料格式為(message,is_spam)\n",
        "        #所有垃圾郵件的數量\n",
        "        num_spams=len([is_spam for message,is_spam in training_set if is_spam])\n",
        "        #所有不是垃圾郵件的數量\n",
        "        num_non_spams=len(training_set)-num_spams\n",
        "        \n",
        "        self.is_spam_probability = float(num_spams)/float(len(training_set))\n",
        "        self.is_not_spam_probability = float(num_non_spams)/float(len(training_set)) \n",
        "        #把training_set裡面的所有字體轉成('Bad',num_is_spam,num_not_spam)\n",
        "        word_counts=count_words(training_set)\n",
        "        self.word_probs=word_probabilities(word_counts,num_spams,num_non_spams,self.k)\n",
        "    def classify(self,message):\n",
        "        return spam_probability(self.word_probs,message, self.is_spam_probability, self.is_not_spam_probability)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tccCP-ghvnKW"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwOlZD5IvnKW"
      },
      "source": [
        "### Fit 訓練集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f9IpeeGWvnKW"
      },
      "source": [
        "classifier=NaiveBayesClassifier()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDbAXPAFvnKW"
      },
      "source": [
        "classifier.train(train_data)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7in0ZLovnKX"
      },
      "source": [
        "### 預測"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA5FmnSmvnKX"
      },
      "source": [
        "\n",
        "classified=[(subject,is_spam,classifier.classify(subject)) for subject,is_spam in test_data]\n",
        "counts=Counter((is_spam,spam_probability>0.5) for _,is_spam,spam_probability in classified)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vO3O781r0Zl",
        "outputId": "031021dd-63c2-4a4e-9614-b2210718ec3e"
      },
      "source": [
        "counts"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({(False, False): 578,\n",
              "         (False, True): 9,\n",
              "         (True, False): 46,\n",
              "         (True, True): 52})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssGRoaXUr80V",
        "outputId": "38e55638-df53-4872-b89a-c77caa67cacf"
      },
      "source": [
        "precision=counts[(True, True)]/(counts[(True, True)]+counts[(False, True)])\n",
        "recall=counts[(True, True)]/(counts[(True, True)]+counts[(True, False)])\n",
        "binary_accuracy = (counts[(True, True)]+counts[(False, False)])/(counts[(False, True)]+counts[(False, False)]+counts[(True, True)]+counts[(True, False)])\n",
        "print('accuracy : {:.2f}%'.format(binary_accuracy*100))\n",
        "print('precision : {:.2f}%'.format(precision*100))\n",
        "print('recall : {:.2f}%'.format(recall*100))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy : 91.97%\n",
            "precision : 85.25%\n",
            "recall : 53.06%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}