{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "pytorch_env",
      "language": "python",
      "name": "pytorch_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Adaboost作業.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwlRwXYSTueR"
      },
      "source": [
        "### 作業目的:了解Ensemble中的Blending與Stacking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02ffOpZLTueX"
      },
      "source": [
        "### Question: 請描述Blending與Stacking的差異\n",
        "\n",
        "Answer:<br>\n",
        "Blending和Stacking最主要的差異在**資料集的切分方式**。不同於Stacking一開始使用Kfold切分訓練資料&驗證資料，Blending是將訓練資料集切出10%作為Holdout_set。<br>而meta model的訓練資料，Stacking**僅使用驗證資料的預測結果**當作特徵;Blending則是使用**Holdout_set的預測結果+原始的Holdout_set特徵**作為全部特徵。<br>\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Stacking<br>\n",
        "step<br>\n",
        "1.訓練資料集→**Kfold**→訓練資料集\\*K + 驗證資料集\\*K。<br>\n",
        "2.利用訓練資料集來訓練第一層的模型-base models(多個不同類型的模型)，再用**驗證資料集和測試資料集預測**。<br>\n",
        "3.將不同模型的**預測結果**整合，變成**新的訓練資料集**和**新的測試資料集**(不合併原始資料)。<br>\n",
        "4.用上個步驟取得的新的訓練資料集訓練第二層的模型-meta model，最後用新的測試資料集來預測結果，取得最終預測。<br>\n",
        "\n",
        "\n",
        "\n",
        "Blending<br>\n",
        "step<br>\n",
        "1.從訓練資料集切一份**Holdout_set**(訓練資料集的10%)。\n",
        "2.利用訓練資料集來訓練第一層的模型-base models(多個不同類型的模型)，再用Holdout_set和測試資料集預測。<br>\n",
        "3.將不同模型的**預測結果**整合，並**合併回原本的Holdout_set和測試資料集**(此時Holdout_set和測試資料集的特徵數=原始資料特徵數+base model 數量)。<br>\n",
        "4.上個步驟取得的Holdout_set作為新的訓練資料集，用來訓練第二層的模型-meta model，最後用新的測試資料集來預測結果，取得最終預測。<br>\n",
        "\n"
      ]
    }
  ]
}