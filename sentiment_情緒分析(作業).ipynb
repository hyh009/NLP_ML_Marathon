{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment_情緒分析(作業).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHTVHbHkzisw"
      },
      "source": [
        "## 題目:電商產品評分文件以機器學習方式分辨是否為正向或負向<br>\n",
        "\n",
        "說明：<br>\n",
        "1.輸入文件 positive.review 和 negative.review，兩者都是XML檔。我們用BeautifulSoup讀進來，擷取review_text，然後用NLTK自建Tokenizer。先產生 word-to-index map 再產生 word-frequency vectors。<br>\n",
        "2.之後 shuffle data 創造 train/test splits，留100個給 test 用。<br>\n",
        "3.接著用Logistic Regression 分類器,找出訓練組和測試組的準確度(Accuracy)。接著我們可以看看每個單字的正負權重，可以訂一個閥值，比方絕對值大於正負0.5，以確認情緒是顯著的。<br>\n",
        "4.最後我們找出根據現有演算法歸類錯誤最嚴重的正向情緒和負向情緒的例子。<br>\n",
        "\n",
        "延伸:可用不同的tokenizer，不同的tokens_to_vector，不同的ML分類器做改進準確率的比較。最後可用您的model去預測unlabeled.review檔的內容。<br>\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "範例程式檔名: sentiment_情緒分析.py，以LogisticRegression 方式完成情緒分析。<br>\n",
        "模組: sklearn, bs4, numpy, nltk<br>\n",
        "輸入檔：stopwords.txt, /electronics 下 positive.review, negative.review<br>\n",
        "成績：辨識百分率<br>\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "注意事項：nltk 需要有 punkt corpus 和 wordnet  資源<br>\n",
        "import nltk<br>\n",
        "nltk.download('punkt')<br>\n",
        "nltk.download('wordnet') <br>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hNH07dCx_zg"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "from future.utils import iteritems\n",
        "from builtins import range\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "stopwords = stopwords.words('english')\n",
        "#nltk.download('stopwords')\n",
        "#nltk.download('punkt')\n",
        "#nltk.download('wordnet')\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "wordnet_lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYlr6q2RyMCR"
      },
      "source": [
        "# 讀正向與負向 reviews\n",
        "# data courtesy of http://www.cs.jhu.edu/~mdredze/datasets/sentiment/index2.html\n",
        "positive_reviews = BeautifulSoup(open('/content/drive/MyDrive/NLP/electronics/positive.review', encoding='utf-8').read(), features=\"html5lib\")\n",
        "positive_reviews = positive_reviews.findAll('review_text')\n",
        "\n",
        "negative_reviews = BeautifulSoup(open('/content/drive/MyDrive/NLP/electronics/negative.review', encoding='utf-8').read(), features=\"html5lib\")\n",
        "negative_reviews = negative_reviews.findAll('review_text')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhzMxYbA2vFy"
      },
      "source": [
        "# 基於nltk自建 tokenizer(使用pos tag)\n",
        "def get_wordnet_pos(word):\n",
        "    \"\"\"將pos_tag結果mapping到lemmatizer中pos的格式\"\"\"\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "def my_tokenizer_with_postag(s):\n",
        "    s = s.lower() # downcase\n",
        "    tokens = nltk.tokenize.word_tokenize(s) # 將字串改為tokens\n",
        "    tokens = [t for t in tokens if len(t) > 2] # 去除短字\n",
        "    tokens = [wordnet_lemmatizer.lemmatize(t,get_wordnet_pos(t)) for t in tokens] # 提取詞幹\n",
        "    tokens = [t for t in tokens if t not in stopwords] # 去除 stopwords\n",
        "    return tokens"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzPCgmsWzZK5"
      },
      "source": [
        "# 基於nltk自建 tokenizer\n",
        "\n",
        "def my_tokenizer(s):\n",
        "    s = s.lower() # downcase\n",
        "    tokens = nltk.tokenize.word_tokenize(s) # 將字串改為tokens\n",
        "    tokens = [t for t in tokens if len(t) > 2] # 去除短字\n",
        "    tokens = [wordnet_lemmatizer.lemmatize(t) for t in tokens] # 提取詞幹\n",
        "    tokens = [t for t in tokens if t not in stopwords] # 去除 stopwords\n",
        "    return tokens"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dkRRmMQziGB",
        "outputId": "1b23449f-fbce-49c6-a190-3aa0392b955f"
      },
      "source": [
        "# 先產生 word-to-index map 再產生 word-frequency vectors\n",
        "# 同時儲存 tokenized 版本未來不需再做 tokenization\n",
        "word_index_map = {}\n",
        "current_index = 0\n",
        "positive_tokenized = [] #儲存每篇正評的tokens\n",
        "negative_tokenized = [] #儲存每篇負評的tokens\n",
        "orig_reviews = [] #儲存所有原始評論\n",
        "\n",
        "for review in positive_reviews:\n",
        "    orig_reviews.append(review.text)\n",
        "    tokens = my_tokenizer(review.text)\n",
        "    positive_tokenized.append(tokens)\n",
        "    for token in tokens:\n",
        "        if token not in word_index_map:\n",
        "            word_index_map[token] = current_index\n",
        "            current_index+=1\n",
        "\n",
        "\n",
        "for review in negative_reviews:\n",
        "    orig_reviews.append(review.text)\n",
        "    tokens = my_tokenizer(review.text)\n",
        "    negative_tokenized.append(tokens)\n",
        "    for token in tokens:\n",
        "        if token not in word_index_map:\n",
        "            word_index_map[token] = current_index\n",
        "            current_index+=1\n",
        "\n",
        "print(\"len(word_index_map):\", len(word_index_map))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len(word_index_map): 11297\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3XMWLm75ptx"
      },
      "source": [
        "# now let's create our input matrices\n",
        "def tokens_to_vector(tokens, label):\n",
        "    x = np.zeros(len(word_index_map) + 1) # 最後一個元素是label\n",
        "    for t in tokens:\n",
        "        i = word_index_map[t]\n",
        "        x[i] += 1\n",
        "    x = x / x.sum() # 正規化數據提升未來準確度\n",
        "    x[-1] = label\n",
        "    return x\n",
        "\n",
        "N = len(positive_tokenized) + len(negative_tokenized)\n",
        "# (N x D+1) 矩陣 - 擺在一塊將來便於shuffle\n",
        "data = np.zeros((N, len(word_index_map) + 1))\n",
        "i = 0\n",
        "for tokens in positive_tokenized:\n",
        "    xy = tokens_to_vector(tokens, 1)\n",
        "    data[i,:] = xy\n",
        "    i += 1\n",
        "\n",
        "for tokens in negative_tokenized:\n",
        "    xy = tokens_to_vector(tokens, 0)\n",
        "    data[i,:] = xy\n",
        "    i += 1"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsXdUOIk7KVf"
      },
      "source": [
        "# shuffle data 創造 train/test splits\n",
        "orig_reviews, data = shuffle(orig_reviews, data)\n",
        "\n",
        "X = data[:,:-1]\n",
        "Y = data[:,-1]\n",
        "\n",
        "# 最後 100 列是測試用\n",
        "Xtrain = X[:-100,]\n",
        "Ytrain = Y[:-100,]\n",
        "Xtest = X[-100:,]\n",
        "Ytest = Y[-100:,]\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReGpEJOK-JwP",
        "outputId": "cf7c01f3-1fe2-4e0e-e503-5de5f963a35f"
      },
      "source": [
        "LR = LogisticRegression(random_state=1)\n",
        "LR.fit(Xtrain, Ytrain)\n",
        "print(\"Train accuracy:\", LR.score(Xtrain, Ytrain))\n",
        "print(\"Test accuracy:\", LR.score(Xtest, Ytest))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 0.7947368421052632\n",
            "Test accuracy: 0.81\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Siz2Q1ZK-lGs",
        "outputId": "71b65e0e-2240-4a91-a2b0-c9473616fa91"
      },
      "source": [
        "# 列出每個字的正負 weight\n",
        "# 用不同的 threshold values!\n",
        "threshold = 0.5\n",
        "for word, index in iteritems(word_index_map):\n",
        "    weight = LR.coef_[0][index]\n",
        "    if weight > threshold or weight < -threshold:\n",
        "        print(word, weight)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unit -0.5915704831501671\n",
            "bad -0.6248628581718502\n",
            "cable 0.5278136456596043\n",
            "time -0.6624396695007301\n",
            "used 0.9742193542402741\n",
            "'ve 0.5961302300635231\n",
            "month -0.6404595335265224\n",
            "problem 0.5237838279780997\n",
            "need 0.5842710324763746\n",
            "good 1.9141913566366175\n",
            "sound 1.1005783405300855\n",
            "like 0.6639907319545435\n",
            "lot 0.6206479032444179\n",
            "n't -1.8547321869367932\n",
            "easy 1.2796688861055274\n",
            "case 0.5584096450685518\n",
            "get -1.0830047256835995\n",
            "use 1.3929140808656175\n",
            "quality 1.1638328539232914\n",
            "company -0.5323035799687027\n",
            "best 0.9280170851000734\n",
            "item -0.9358914753079649\n",
            "working -0.5139693053769487\n",
            "well 1.010490058294626\n",
            "wa -1.2679184563257488\n",
            "perfect 0.901549496751304\n",
            "fast 0.7629842222419804\n",
            "ha 0.6077946661799492\n",
            "price 2.254989164770666\n",
            "great 3.3557038918586577\n",
            "money -0.8610392889022679\n",
            "memory 0.7493247570250994\n",
            "would -0.629000510489913\n",
            "buy -0.948243208325204\n",
            "worked -0.8117477438572105\n",
            "happy 0.5228389621823937\n",
            "pretty 0.5491661788996735\n",
            "doe -1.0282908667135213\n",
            "two -0.6328203074147392\n",
            "highly 0.8309417932859127\n",
            "recommend 0.6228594757489271\n",
            "first -0.6388955827216269\n",
            "customer -0.6050503141413753\n",
            "support -0.7873185939056582\n",
            "little 0.6660757662902715\n",
            "returned -0.593116114470805\n",
            "excellent 1.2068038351837456\n",
            "love 0.8539025001438793\n",
            "small 0.6101517836812431\n",
            "week -0.5640444984294797\n",
            "using 0.5513930745985441\n",
            "thing -0.8962539430323303\n",
            "even -0.7355671731482348\n",
            "poor -0.6779118378519505\n",
            "tried -0.6478082735861164\n",
            "back -1.4342075861543706\n",
            "try -0.5428636819518081\n",
            "comfortable 0.5090685445415222\n",
            "speaker 0.8197271161787768\n",
            "warranty -0.5470648463262792\n",
            "paper 0.5363177445334923\n",
            "return -0.9011288946895853\n",
            "waste -0.8925006950624019\n",
            "refund -0.516250116138334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oc4TyJKH-tlN"
      },
      "source": [
        "# 找出歸類錯誤的例子\n",
        "preds = LR.predict(X)\n",
        "P = LR.predict_proba(X)[:,1] # p(y = 1 | x) #取出預測結果為1的機率"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8JV9Zkf-rVF",
        "outputId": "cdf49dfe-6577-41ab-ce73-364ddb03a8c7"
      },
      "source": [
        "# 只列出最糟的\n",
        "minP_whenYis1 = 1\n",
        "maxP_whenYis0 = 0\n",
        "wrong_positive_review = None\n",
        "wrong_negative_review = None\n",
        "wrong_positive_prediction = None\n",
        "wrong_negative_prediction = None\n",
        "for i in range(N):\n",
        "    p = P[i]\n",
        "    y = Y[i]\n",
        "    if y == 1 and p < 0.5: #答案為1，但預測為1的機率小於0.5 == FN\n",
        "        if p < minP_whenYis1:\n",
        "            wrong_positive_review = orig_reviews[i]\n",
        "            wrong_positive_prediction = preds[i]\n",
        "            minP_whenYis1 = p\n",
        "            idx_p=i\n",
        "    elif y == 0 and p > 0.5: #答案為0，但預測為1的機率大於0.5 == FP\n",
        "        if p > maxP_whenYis0:\n",
        "            wrong_negative_review = orig_reviews[i]\n",
        "            wrong_negative_prediction = preds[i]\n",
        "            maxP_whenYis0 = p\n",
        "            idx_n=i\n",
        "\n",
        "print(\"Most wrong positive review is NO.%s (prob = %s, pred = %s):\" % (idx_p,minP_whenYis1, wrong_positive_prediction))\n",
        "print(wrong_positive_review)\n",
        "print(\"Most wrong negative review is NO.%s (prob = %s, pred = %s):\" % (idx_n, maxP_whenYis0, wrong_negative_prediction))\n",
        "print(wrong_negative_review)\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most wrong positive review is NO.461 (prob = 0.40135203639398737, pred = 0.0):\n",
            "\n",
            "This was a defective unit. Got new unit and it works as expected\n",
            "\n",
            "Most wrong negative review is NO.1456 (prob = 0.6676719016677286, pred = 1.0):\n",
            "\n",
            "The Voice recorder meets all my expectations and more\n",
            "Easy to use, easy to transfer great results\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}